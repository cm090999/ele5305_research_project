{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook for BirdCLEF2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all Dependencies (1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchaudio\n",
    "import torchvision.transforms as transforms\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import WeightedRandomSampler\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "import sklearn.metrics\n",
    "from tqdm import tqdm\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import random\n",
    "import time\n",
    "import copy\n",
    "import logging\n",
    "import bisect\n",
    "import json\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define a CONFIG class containing all relevant hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### DO NOT CHANGE UNLESS RE-GENERATING DATASET IMAGES ###\n",
    "class Config_Mel():\n",
    "    def __init__(self) -> None:\n",
    "        \n",
    "        # Device\n",
    "        self.device = 'cpu'\n",
    "        \n",
    "        # Dataset Path\n",
    "        self.birdclef2023 = 'birdclef-2023'\n",
    "\n",
    "        # Out path\n",
    "        self.outpath_images = self.birdclef2023 + '_MelSpectrograms'\n",
    "\n",
    "        self.melSpecTransform = torchaudio.transforms.AmplitudeToDB()\n",
    "\n",
    "        # Audio Features\n",
    "        self.sample_rate = 32000\n",
    "        self.n_fft=2048\n",
    "        self.f_min=40\n",
    "        self.f_max=15000\n",
    "        self.hop_length=512\n",
    "        self.n_mels=128\n",
    "        self.mel_args = {'sample_rate': self.sample_rate,\n",
    "                         'n_fft': self.n_fft,\n",
    "                         'f_min': self.f_min,\n",
    "                         'f_max': self.f_max,\n",
    "                         'hop_length': self.hop_length,\n",
    "                         'n_mels': self.n_mels}\n",
    "### DO NOT CHANGE UNLESS RE-GENERATING DATASET IMAGES ###\n",
    "\n",
    "class Config():\n",
    "    def __init__(self) -> None:\n",
    "\n",
    "        self.run_environment = 'local' # 'kaggle' 'local' 'colab'\n",
    "        self.load_pretrained_weights = False\n",
    "        self.rerun_split = False\n",
    "        self.use_5_second_dataset = True\n",
    "        self.uniform_sampler = True\n",
    "        self.training_data_per_epoch = 0.2\n",
    "        self.soft_second_label = 0.3\n",
    "        self.class_weighting = True\n",
    "        self.softmax_prob = True\n",
    "        self.use_mixup = True\n",
    "        self.criterion = nn.CrossEntropyLoss # nn.BCEWithLogitsLoss\n",
    "        self.epochs = 20\n",
    "        self.masking = True\n",
    "\n",
    "        # Device\n",
    "        if (self.run_environment == 'kaggle') or (self.run_environment == 'colab'):\n",
    "            self.device = 'cuda'\n",
    "        else:\n",
    "            self.device = 'cpu'\n",
    "        \n",
    "        # Dataset Path\n",
    "        self.birdclef2023 = 'birdclef-2023'\n",
    "        if self.run_environment == 'kaggle':\n",
    "            self.birdclef2023_melspectrograms = '/kaggle/input/birdclef-2023-melspectrograms/birdclef-2023_MelSpectrograms'\n",
    "            self.birdclef2023_melspectrograms_5_seconds = '/kaggle/input/birdclef-2023-melspectrograms-5-seconds/birdclef-2023_MelSpectrograms_5_seconds'\n",
    "        elif self.run_environment == 'local':\n",
    "            self.birdclef2023_melspectrograms = '/home/colin/elec5305/ele5305_research_project/birdclef-2023_MelSpectrograms'\n",
    "            self.birdclef2023_melspectrograms_5_seconds = '/home/colin/elec5305/ele5305_research_project/birdclef-2023_MelSpectrograms_5_seconds'\n",
    "        elif self.run_environment == 'colab':\n",
    "            self.birdclef2023_melspectrograms = ''\n",
    "\n",
    "        # Out path\n",
    "        if self.run_environment == 'kaggle':\n",
    "            self.outpath = '/kaggle/working/results'\n",
    "        elif self.run_environment == 'local':\n",
    "            self.outpath = 'results'\n",
    "        elif self.run_environment == 'colab':\n",
    "            self.outpath = ''\n",
    "\n",
    "        # Train/Validation Split \n",
    "        self.val_frac = 0.1\n",
    "\n",
    "        # Dataloader options\n",
    "        self.num_workers = 2\n",
    "        self.train_batch_size = 64\n",
    "        self.valid_batch_size = 32\n",
    "\n",
    "        # Model name\n",
    "        self.model_name = 'tf_efficientnet_b0_ns'\n",
    "        # Pretrained\n",
    "        if self.run_environment == 'kaggle':\n",
    "            self.pretrained_weights = '/kaggle/input/weigths/model_weights.pth'\n",
    "        elif self.run_environment == 'local':\n",
    "            self.pretrained_weights = '/home/colin/elec5305/ele5305_research_project/weights/model_weights.pth'\n",
    "\n",
    "\n",
    "        # Optimizer Settings\n",
    "        self.lr=5e-4\n",
    "        self.weight_decay = 1e-3\n",
    "        self.momentum=0.9\n",
    "        self.optimizer = 'adam' # 'adam', 'sgd'\n",
    "\n",
    "        self.scheduler = 'cosineannealing'\n",
    "        self.eta_min = 1e-6\n",
    "        self.T_mult = 1\n",
    "        self.last_epoch = -1\n",
    "        self.use_amp = False\n",
    "\n",
    "        self.mixup_alpha = 0.2 \n",
    "\n",
    "        # Training Settings\n",
    "        self.print_every_n_batches = 25\n",
    "        self.patience = 5\n",
    "        self.fix_features = False\n",
    "\n",
    "        # Image Transforms\n",
    "        self.train_transforms = torchvision.transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                    torchvision.transforms.RandomResizedCrop(size=(128, 312), scale = (0.75, 1.0), antialias=True), \n",
    "                    ])\n",
    "        \n",
    "        self.val_transforms = torchvision.transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                    torchvision.transforms.RandomResizedCrop(size=(128, 312), scale = (0.75, 1.0), antialias=True), \n",
    "                    ])\n",
    "        \n",
    "        self.test_transforms = torchvision.transforms.Compose([\n",
    "                    transforms.ToTensor(),\n",
    "                    # torchvision.transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "                    # torchvision.transforms.Resize(size=(224, 224), antialias=True),  # Or Resize(antialias=True)\n",
    "                    ])\n",
    "\n",
    "        # Audio Transforms\n",
    "        self.train_transforms_audio = None\n",
    "        \n",
    "        self.val_transforms_audio = None\n",
    "        \n",
    "        self.test_transforms_audio = None\n",
    "\n",
    "\n",
    "        # Audio Features\n",
    "        self.sample_rate = 32000\n",
    "        self.period = 5\n",
    "\n",
    "        # Mel Spectrogram Parameters\n",
    "        self.n_fft=2048\n",
    "        self.f_min=40\n",
    "        self.f_max=15000\n",
    "        self.hop_length=512\n",
    "        self.n_mels=128\n",
    "        self.mel_args = {'n_fft': self.n_fft,\n",
    "                         'f_min': self.f_min,\n",
    "                         'f_max': self.f_max,\n",
    "                         'hop_length': self.hop_length,\n",
    "                         'n_mels': self.n_mels}\n",
    "        \n",
    "CONFIG = Config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.run_environment == 'colab':\n",
    "    from google.colab import drive\n",
    "    drive.mount('/content/drive')\n",
    "\n",
    "    notebook_path = 'My Drive/elec5305'\n",
    "\n",
    "    env_path = f'/content/drive/{notebook_path}'\n",
    "    #Â Add the handout folder to python paths\n",
    "    if env_path not in sys.path:\n",
    "        sys.path.append(env_path)\n",
    "\n",
    "    # zip_path = os.path.join(env_path, 'birdclef-2023_MelSpectrograms.zip')\n",
    "    zip_path = '/content/drive/MyDrive/elec5305/birdclef-2023_MelSpectrograms.zip'\n",
    "    shutil.unpack_archive(zip_path, \"content/\")\n",
    "    print(zip_path)\n",
    "    # !unzip zip_path -d \"/content\"\n",
    "\n",
    "    # Dataset path\n",
    "    CONFIG.birdclef2023_melspectrograms = '/content/content/birdclef-2023_MelSpectrograms'\n",
    "\n",
    "    # Output path\n",
    "    CONFIG.outpath = os.path.join(env_path, 'results')\n",
    "    os.makedirs(CONFIG.outpath, exist_ok=True)# !pip install --force-reinstall numpy==1.22.1\n",
    "    \n",
    "    %pip install -q torchtoolbox timm\n",
    "\n",
    "    %pip install timm torchtoolbox"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import all dependencies (2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.run_environment != 'local':\n",
    "    # !pip install --force-reinstall numpy==1.22.1\n",
    "    %pip install -q torchtoolbox timm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtoolbox.tools import mixup_data, mixup_criterion\n",
    "from torch.nn.functional import cross_entropy\n",
    "import timm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Mel_Classifier(torch.nn.Module):\n",
    "    def __init__(self, model_name, num_classes = 264, pretrained = True):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.backbone = timm.create_model(model_name, pretrained=pretrained)\n",
    "\n",
    "        if 'res' in model_name:\n",
    "            self.in_features = self.backbone.fc.in_features\n",
    "            self.backbone.fc = nn.Linear(self.in_features, num_classes)\n",
    "        elif 'dense' in model_name:\n",
    "            self.in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Linear(self.in_features, num_classes)\n",
    "        elif 'efficientnet' in model_name:\n",
    "            self.in_features = self.backbone.classifier.in_features\n",
    "            self.backbone.classifier = nn.Sequential(\n",
    "                nn.Linear(self.in_features, num_classes)\n",
    "            )\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.backbone(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Dataloader Class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEF2023_MelSpec_Dataset(torch.nn.Module):\n",
    "    def __init__(self, dataset_path, train_flag = None, inherited_species_list = None,*args, **kwargs) -> None:\n",
    "\n",
    "        # Default values\n",
    "        self.sample_rate = kwargs.get('sample_rate', 32000)\n",
    "        self.n_fft = kwargs.get('n_fft', 2048)\n",
    "        self.f_min = kwargs.get('f_min', 40)\n",
    "        self.f_max = kwargs.get('f_max', 15000)\n",
    "        self.hop_length = kwargs.get('hop_length', 512)\n",
    "        self.n_mels = kwargs.get('n_mels', 128)\n",
    "        self.period = kwargs.get('period', 5)\n",
    "        self.device = kwargs.get('device', 'cpu')\n",
    "        self.transform = kwargs.get('transform', transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]))\n",
    "         \n",
    "        # Save path of dataset\n",
    "        self.datapath = dataset_path\n",
    "\n",
    "        # Get metadata\n",
    "        if train_flag is None:\n",
    "            csv_name = 'train_metadata.csv'\n",
    "        elif train_flag == 'train':\n",
    "            csv_name = 'TRAIN_train_metadata.csv'\n",
    "        elif train_flag == 'valid':\n",
    "            csv_name = 'VALID_train_metadata.csv'\n",
    "\n",
    "        self.df = pd.read_csv(os.path.join(dataset_path, csv_name))\n",
    "\n",
    "        # Get species list\n",
    "        if inherited_species_list is None:\n",
    "            self.species = list(set(self.df['primary_label']))\n",
    "        else:\n",
    "            self.species = inherited_species_list\n",
    "\n",
    "        # Get time per pixel\n",
    "        self.time_per_pixel = self.hop_length / self.sample_rate\n",
    "\n",
    "        # Image Width\n",
    "        self.new_width = int(self.period / self.time_per_pixel)\n",
    "\n",
    "        # Get number of cut images per full image\n",
    "        self.get_shortened_image()\n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "    def get_shortened_image(self):\n",
    "\n",
    "        old_len = len(list(self.df['primary_label']))\n",
    "        number_of_images_per_image = [0] * old_len\n",
    "\n",
    "        cumulative_images_count = 0\n",
    "        cumulative_list = [0] * old_len\n",
    "\n",
    "        for i in tqdm(range(old_len), desc=\"Processing Images\"):\n",
    "            dict_idx = dict(self.df.iloc[i])\n",
    "\n",
    "            # Load image\n",
    "            rel_img_path = dict_idx['image_path']\n",
    "            ful_img_path = os.path.join(self.datapath,rel_img_path)\n",
    "            image = Image.open(ful_img_path)\n",
    "\n",
    "            # Get image shape\n",
    "            width, height = image.size\n",
    "\n",
    "            # How many images of self.period length fit in image?\n",
    "            n_imgs = width // self.new_width\n",
    "\n",
    "            # Put to list\n",
    "            number_of_images_per_image[i] = n_imgs\n",
    "\n",
    "            # Calculate the cumulative count\n",
    "            cumulative_images_count += n_imgs\n",
    "\n",
    "            # Put to list\n",
    "            cumulative_list[i] = cumulative_images_count - 1\n",
    "\n",
    "        # Add number_of_images_per_image as a new column to the DataFrame\n",
    "        self.df['cumulative_images'] = cumulative_list\n",
    "\n",
    "        return\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        # length = self.df['cumulative_images'][-1]\n",
    "        length = self.df['cumulative_images'].iloc[-1]\n",
    "        return length\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Get the 'cumulative_list' values as a sorted list\n",
    "        cumulative_list_values = self.df['cumulative_images'].tolist()\n",
    "\n",
    "        # Use binary search to find the index of the next smallest value to idx\n",
    "        row_index = bisect.bisect_left(cumulative_list_values, idx)\n",
    "        cumulative_value_left = 0\n",
    "        if row_index == 0:\n",
    "            cumulative_value_left = 0\n",
    "        else:\n",
    "            cumulative_value_left = self.df['cumulative_images'].iloc[row_index-1] + 1\n",
    "        sub_idx = idx - cumulative_value_left\n",
    "\n",
    "        # Get row in df\n",
    "        dict_idx = dict(self.df.iloc[row_index])\n",
    "\n",
    "        # Calculate image crop start pixel based on sub_idx\n",
    "        px_start = sub_idx * self.new_width\n",
    "\n",
    "        # Get labels as torch tensors\n",
    "        primary_label = torch.tensor([1 if dict_idx['primary_label'] == label else 0 for label in self.species],dtype=float)\n",
    "        secondary_label = torch.tensor([1 if label in dict_idx['secondary_labels'] else 0 for label in self.species], dtype=float)\n",
    "        combined_label = self._prepare_target(main_tgt=primary_label, sec_tgt=secondary_label)\n",
    "        dict_idx['combined_label_tensor'] = combined_label\n",
    "        dict_idx['primary_label_tensor'] = primary_label\n",
    "        dict_idx['secondary_label_tensor'] = secondary_label\n",
    "\n",
    "        # Load image\n",
    "        rel_img_path = dict_idx['image_path']\n",
    "        ful_img_path = os.path.join(self.datapath,rel_img_path)\n",
    "        image = Image.open(ful_img_path)\n",
    "        image = self.crop_image(image = image, startPixel = px_start)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        dict_idx['mel_spec'] = image\n",
    "    \n",
    "        return image.float(), primary_label.float()\n",
    "    \n",
    "\n",
    "    def crop_image(self, image, startPixel):\n",
    "        image = image.crop((startPixel, 0, startPixel + self.new_width, image.height))\n",
    "        return image\n",
    "\n",
    "\n",
    "    # https://github.com/VSydorskyy/BirdCLEF_2023_1st_place/blob/main/code_base/datasets/wave_dataset.py, changed\n",
    "    def _prepare_target(self, main_tgt, sec_tgt, all_labels=None):\n",
    "        all_tgt = main_tgt + sec_tgt\n",
    "        all_tgt = torch.clamp(all_tgt, 0.0, 1.0)\n",
    "        return all_tgt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BirdCLEF2023_MelSpec_5_seconds_Dataset(torch.nn.Module):\n",
    "    def __init__(self, dataset_path, train_flag = None, masking = True, inherited_species_list = None,*args, **kwargs) -> None:\n",
    "\n",
    "        # Default values\n",
    "        self.sample_rate = kwargs.get('sample_rate', 32000)\n",
    "        self.n_fft = kwargs.get('n_fft', 2048)\n",
    "        self.f_min = kwargs.get('f_min', 40)\n",
    "        self.f_max = kwargs.get('f_max', 15000)\n",
    "        self.hop_length = kwargs.get('hop_length', 512)\n",
    "        self.n_mels = kwargs.get('n_mels', 128)\n",
    "        self.period = kwargs.get('period', 5)\n",
    "        self.device = kwargs.get('device', 'cpu')\n",
    "        self.soft_second_label = kwargs.get('soft_second_label', 0.0)\n",
    "        self.transform = kwargs.get('transform', transforms.Compose([transforms.ToTensor(), transforms.Normalize(mean=(0.485, 0.456, 0.406), std=(0.229, 0.224, 0.225))]))\n",
    "         \n",
    "        # Save path of dataset\n",
    "        self.datapath = dataset_path\n",
    "        self.masking = masking\n",
    "\n",
    "        # Get metadata\n",
    "        if train_flag is None:\n",
    "            csv_name = 'train_metadata.csv'\n",
    "        elif train_flag == 'train':\n",
    "            csv_name = 'TRAIN_train_metadata.csv'\n",
    "        elif train_flag == 'valid':\n",
    "            csv_name = 'VALID_train_metadata.csv'\n",
    "\n",
    "        self.df = pd.read_csv(os.path.join(dataset_path, csv_name))\n",
    "\n",
    "        # Get species list\n",
    "        if inherited_species_list is None:\n",
    "            self.species = list(set(self.df['primary_label']))\n",
    "        else:\n",
    "            self.species = inherited_species_list\n",
    "        \n",
    "        return\n",
    "    \n",
    "\n",
    "    def __len__(self):\n",
    "        # length = self.df['cumulative_images'][-1]\n",
    "        length = len(list(self.df['primary_label']))\n",
    "        return length\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "\n",
    "        # Get row in df\n",
    "        dict_idx = dict(self.df.iloc[idx])\n",
    "\n",
    "        # Get labels as torch tensors\n",
    "        primary_label = torch.tensor([1 if dict_idx['primary_label'] == label else 0 for label in self.species],dtype=float)\n",
    "        secondary_label = torch.tensor([1 if label in dict_idx['secondary_labels'] else 0 for label in self.species], dtype=float)\n",
    "        combined_label = self._prepare_target(main_tgt=primary_label, sec_tgt=secondary_label)\n",
    "        dict_idx['combined_label_tensor'] = combined_label\n",
    "        dict_idx['primary_label_tensor'] = primary_label\n",
    "        dict_idx['secondary_label_tensor'] = secondary_label\n",
    "\n",
    "        # Load image\n",
    "        rel_img_path = dict_idx['image_path']\n",
    "        ful_img_path = os.path.join(self.datapath,rel_img_path)\n",
    "        image = Image.open(ful_img_path)\n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        if (self.masking == True) and (torch.rand(1) >= 0.5):\n",
    "            image = torchaudio.transforms.FrequencyMasking(\n",
    "                freq_mask_param=image.shape[1] // 5\n",
    "            )(image)\n",
    "            image = torchaudio.transforms.TimeMasking(\n",
    "                time_mask_param=image.shape[2] // 5\n",
    "            )(image)\n",
    "    \n",
    "        dict_idx['mel_spec'] = image\n",
    "\n",
    "        return image.float(), primary_label.float()\n",
    "\n",
    "    # https://github.com/VSydorskyy/BirdCLEF_2023_1st_place/blob/main/code_base/datasets/wave_dataset.py, changed\n",
    "    def _prepare_target(self, main_tgt, sec_tgt, all_labels=None):\n",
    "        all_tgt = main_tgt + sec_tgt * self.soft_second_label\n",
    "        all_tgt = torch.clamp(all_tgt, 0.0, 1.0)\n",
    "        return all_tgt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a Training/Validation Split Scheme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/nischaydnk/split-creating-melspecs-stage-1\n",
    "def birds_stratified_split(df, target_col, test_size=0.2):\n",
    "    class_counts = df[target_col].value_counts()\n",
    "    low_count_classes = class_counts[class_counts < 2].index.tolist() ### Birds with single counts\n",
    "\n",
    "    df['train'] = df[target_col].isin(low_count_classes)\n",
    "\n",
    "    train_df, val_df = train_test_split(df[~df['train']], test_size=test_size, stratify=df[~df['train']][target_col], random_state=42)\n",
    "\n",
    "    train_df = pd.concat([train_df, df[df['train']]], axis=0).reset_index(drop=True)\n",
    "\n",
    "    # Remove the 'valid' column\n",
    "    train_df.drop('train', axis=1, inplace=True)\n",
    "    val_df.drop('train', axis=1, inplace=True)\n",
    "\n",
    "    return train_df, val_df\n",
    "\n",
    "\n",
    "def save_df_as_csv(df, csv_name):\n",
    "    df.to_csv(csv_name, index=False)\n",
    "    return\n",
    "\n",
    "\n",
    "def create_split_and_save(df_path, val_frac):\n",
    "\n",
    "    # Load dataframe\n",
    "    df = pd.read_csv(os.path.join(df_path, 'train_metadata.csv'))\n",
    "\n",
    "    # Get Split\n",
    "    train_df, val_df = birds_stratified_split(df=df, target_col='primary_label', test_size=val_frac)\n",
    "\n",
    "    # Save metadata\n",
    "    os.path.join(df_path, 'TRAIN_train_metadata.csv')\n",
    "    save_df_as_csv(train_df, os.path.join(df_path, 'TRAIN_train_metadata.csv'))\n",
    "    save_df_as_csv(val_df, os.path.join(df_path, 'VALID_train_metadata.csv'))\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.rerun_split == True:\n",
    "    create_split_and_save(df_path=CONFIG.birdclef2023_melspectrograms_5_seconds, val_frac=CONFIG.val_frac)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if CONFIG.rerun_split == True:\n",
    "    create_split_and_save(df_path=CONFIG.birdclef2023_melspectrograms, val_frac=CONFIG.val_frac)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Uniform Sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_uniformSampler(dataset):\n",
    "    n_data = len(dataset)\n",
    "    classes_lsit = dataset.species\n",
    "\n",
    "    count_int = [0] * len(classes_lsit)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        species_index = classes_lsit.index(dataset.df.iloc[i]['primary_label'])\n",
    "        count_int[species_index] += 1\n",
    "\n",
    "    class_weights = np.array(count_int) / n_data\n",
    "\n",
    "    sample_weights = [0] * n_data\n",
    "\n",
    "    for i in range(n_data):\n",
    "        species_index = classes_lsit.index(dataset.df.iloc[i]['primary_label'])\n",
    "        sample_weights[i] = class_weights[species_index]\n",
    "\n",
    "    sampler = WeightedRandomSampler(weights=sample_weights, num_samples=n_data)\n",
    "\n",
    "    return sampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_class_weights(dataset):\n",
    "    n_data = len(dataset)\n",
    "    classes_lsit = dataset.species\n",
    "\n",
    "    count_int = [0] * len(classes_lsit)\n",
    "\n",
    "    for i in range(len(dataset)):\n",
    "        species_index = classes_lsit.index(dataset.df.iloc[i]['primary_label'])\n",
    "        count_int[species_index] += 1\n",
    "\n",
    "    class_weights = np.array(count_int) / n_data * len(classes_lsit)\n",
    "\n",
    "    return class_weights"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Make Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get species list\n",
    "if CONFIG.use_5_second_dataset == False:\n",
    "    df_all = pd.read_csv(os.path.join(CONFIG.birdclef2023_melspectrograms, 'train_metadata.csv'))\n",
    "else:\n",
    "    df_all = pd.read_csv(os.path.join(CONFIG.birdclef2023_melspectrograms_5_seconds, 'train_metadata.csv'))\n",
    "species_list = list(set(df_all['primary_label']))\n",
    "\n",
    "# Initialize Datasets\n",
    "train_class_kwargs = {  'sample_rate': CONFIG.sample_rate,\n",
    "                        'n_fft': CONFIG.n_fft,\n",
    "                        'f_min': CONFIG.f_min,\n",
    "                        'f_max': CONFIG.f_max,\n",
    "                        'hop_length': CONFIG.hop_length,\n",
    "                        'n_mels': CONFIG.n_mels,\n",
    "                        'period': CONFIG.period,\n",
    "                        'device': CONFIG.device,\n",
    "                        'transform': CONFIG.train_transforms,\n",
    "                        'soft_second_label': CONFIG.soft_second_label\n",
    "                     }\n",
    "\n",
    "valid_class_kwargs = {   'sample_rate': CONFIG.sample_rate,\n",
    "                        'n_fft': CONFIG.n_fft,\n",
    "                        'f_min': CONFIG.f_min,\n",
    "                        'f_max': CONFIG.f_max,\n",
    "                        'hop_length': CONFIG.hop_length,\n",
    "                        'n_mels': CONFIG.n_mels,\n",
    "                        'period': CONFIG.period,\n",
    "                        'device': CONFIG.device,\n",
    "                        'transform': CONFIG.val_transforms\n",
    "                    }\n",
    "\n",
    "if CONFIG.use_5_second_dataset == False:\n",
    "    train_dataset = BirdCLEF2023_MelSpec_Dataset(CONFIG.birdclef2023_melspectrograms, inherited_species_list = species_list, **train_class_kwargs, train_flag='train')\n",
    "    valid_dataset = BirdCLEF2023_MelSpec_Dataset(CONFIG.birdclef2023_melspectrograms, inherited_species_list = species_list, **valid_class_kwargs, train_flag='valid')\n",
    "else:\n",
    "    train_dataset = BirdCLEF2023_MelSpec_5_seconds_Dataset(CONFIG.birdclef2023_melspectrograms_5_seconds, masking = CONFIG.masking, inherited_species_list = species_list, **train_class_kwargs, train_flag='train')\n",
    "    valid_dataset = BirdCLEF2023_MelSpec_5_seconds_Dataset(CONFIG.birdclef2023_melspectrograms_5_seconds, masking = CONFIG.masking, inherited_species_list = species_list, **valid_class_kwargs, train_flag='valid')\n",
    "\n",
    "if CONFIG.uniform_sampler == False:\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,num_workers=CONFIG.num_workers, batch_size=CONFIG.train_batch_size, shuffle = True, pin_memory = True)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,num_workers=CONFIG.num_workers, batch_size=CONFIG.valid_batch_size, shuffle = True, pin_memory = True)\n",
    "else:\n",
    "    train_sampler = make_uniformSampler(dataset=train_dataset)\n",
    "    valid_sampler = make_uniformSampler(dataset=valid_dataset)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset,num_workers=CONFIG.num_workers, batch_size=CONFIG.train_batch_size, pin_memory = True, sampler=train_sampler)\n",
    "    valid_loader = torch.utils.data.DataLoader(dataset=valid_dataset,num_workers=CONFIG.num_workers, batch_size=CONFIG.valid_batch_size, pin_memory = True, sampler=valid_sampler)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize some spectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_batch(img_ds, num_items, num_rows, num_cols, predict_arr=None):\n",
    "    fig = plt.figure(figsize=(12, 6))    \n",
    "    img_index = np.random.randint(0, len(img_ds)-1, num_items)\n",
    "    for index, img_index in enumerate(img_index):  # list first 9 images\n",
    "        dict_idx = img_ds[img_index]        \n",
    "        img, lb = dict_idx    \n",
    "        ax = fig.add_subplot(num_rows, num_cols, index + 1, xticks=[], yticks=[])\n",
    "        if isinstance(img, torch.Tensor):\n",
    "            img = img.detach().numpy()\n",
    "        if isinstance(img, np.ndarray):\n",
    "            img = img.transpose(1, 2, 0)\n",
    "            ax.imshow(img)        \n",
    "            \n",
    "        title = f\"Spec\"\n",
    "        ax.set_title(title)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_batch(train_dataset, 8, 2, 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Some Statistics on Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train, n_val = len(train_dataset), len(valid_dataset)\n",
    "classes_lsit = train_dataset.species\n",
    "\n",
    "count_int_val = [0] * len(classes_lsit)\n",
    "count_int_train = [0] * len(classes_lsit)\n",
    "\n",
    "for i in range(len(train_dataset)):\n",
    "    species_index = species_list.index(train_dataset.df.iloc[i]['primary_label'])\n",
    "    count_int_train[species_index] += 1\n",
    "for i in range(len(valid_dataset)):\n",
    "    species_index = species_list.index(valid_dataset.df.iloc[i]['primary_label'])\n",
    "    count_int_val[species_index] += 1\n",
    "\n",
    "count_int_train, count_int_val = np.array(count_int_train), np.array(count_int_val)\n",
    "\n",
    "# Plot code SOURCE: https://matplotlib.org/stable/gallery/lines_bars_and_markers/barchart.html#sphx-glr-gallery-lines-bars-and-markers-barchart-py\n",
    "\n",
    "penguin_means = {\n",
    "    'Training Set': count_int_train / n_train,\n",
    "    'Validation Set': count_int_val / n_val\n",
    "}\n",
    "\n",
    "\n",
    "\n",
    "x = np.arange(len(classes_lsit))  # the label locations\n",
    "width = 0.35  # the width of the bars\n",
    "multiplier = 0\n",
    "\n",
    "fig, ax = plt.subplots(layout='constrained', figsize=(24,12))\n",
    "colors = ['crimson','midnightblue']\n",
    "for i,(attribute, measurement) in enumerate(penguin_means.items()):\n",
    "    offset = width * i\n",
    "    rects = ax.bar(x + offset, measurement, width, label=attribute, color=colors[i], alpha=0.7)\n",
    "    multiplier += 1\n",
    "\n",
    "# Add some text for labels, title and custom x-axis tick labels, etc.\n",
    "ax.set_ylabel('Fraction of Dataset [-]')\n",
    "ax.set_title('Distribution of Classes in Validation and Training Data')\n",
    "\n",
    "# ax.set_xticks(x + width / 2, classes_lsit)\n",
    "# ax.set_xticks(x + width / 2)\n",
    "\n",
    "ax.legend(loc='upper left', ncols=2)\n",
    "ax.set_ylim(0, 0.1)\n",
    "plt.grid(color='gray', linestyle='--', linewidth=0.5, alpha=0.5)\n",
    "\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Metric Function as on Kaggle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def padded_cmap(solution, submission, padding_factor=5):\n",
    "    solution = solution.drop(['row_id'], axis=1, errors='ignore')\n",
    "    submission = submission.drop(['row_id'], axis=1, errors='ignore')\n",
    "    new_rows = []\n",
    "    for i in range(padding_factor):\n",
    "        new_rows.append([1 for i in range(len(solution.columns))])\n",
    "    new_rows = pd.DataFrame(new_rows)\n",
    "    new_rows.columns = solution.columns\n",
    "    padded_solution = pd.concat([solution, new_rows]).reset_index(drop=True).copy()\n",
    "    padded_submission = pd.concat([submission, new_rows]).reset_index(drop=True).copy()\n",
    "    score = sklearn.metrics.average_precision_score(\n",
    "        padded_solution.values,\n",
    "        padded_submission.values,\n",
    "        average='macro',\n",
    "    )\n",
    "    return score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define Training Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_logger(final_output_path):\n",
    "    log_file = '{}.log'.format(time.strftime('%Y-%m-%d-%H-%M'))\n",
    "    head = '%(asctime)-15s %(message)s'\n",
    "    logging.basicConfig(filename=os.path.join(final_output_path, log_file),\n",
    "                        format=head)\n",
    "    clogger = logging.getLogger()\n",
    "    clogger.setLevel(logging.INFO)\n",
    "    # add handler\n",
    "    # print to stdout and log file\n",
    "    ch = logging.StreamHandler(sys.stdout)\n",
    "    ch.setLevel(logging.INFO)\n",
    "    formatter = logging.Formatter('%(asctime)s - %(name)s - %(levelname)s - %(message)s')\n",
    "    ch.setFormatter(formatter)\n",
    "    clogger.addHandler(ch)\n",
    "    return clogger\n",
    "\n",
    "def train_with_mixup(X, y, y_pred, criterion):\n",
    "    X, y_a, y_b, lam = mixup_data(X, y, alpha=CONFIG.mixup_alpha)\n",
    "    loss_mixup = mixup_criterion(criterion, y_pred, y_a, y_b, lam) #cross_entropy\n",
    "    return loss_mixup\n",
    "\n",
    "def train_net(net, trainloader, valloader, logging, criterion, optimizer, scheduler, epochs=1, patience = 3, savePth = 'project2_weights.pth', print_every_samples = 20, device = 'cpu'):\n",
    "\n",
    "    logging.info('Using device: {}'.format(device))\n",
    "    net.to(device)\n",
    "    criterion.to(device)\n",
    "\n",
    "    if CONFIG.softmax_prob == True:\n",
    "        toProb = torch.nn.Softmax(dim=1)\n",
    "    else:\n",
    "        toProb = torch.nn.Identity()\n",
    "\n",
    "    # Automatic Mixed Precision\n",
    "    if CONFIG.use_amp:\n",
    "        scaler = torch.cuda.amp.GradScaler(enabled=CONFIG.use_amp)\n",
    "\n",
    "    validation_loss_list = [0] * epochs\n",
    "    training_loss_list = [0] * epochs\n",
    "    validation_accuracy_list = [0] * epochs\n",
    "    training_accuracy_list = [0] * epochs\n",
    "    cmap_5_list = [0] * epochs\n",
    "\n",
    "    best_state_dictionary = None\n",
    "    best_validation_cmap = 0.0\n",
    "    inertia = 0\n",
    "    for epoch in range(epochs):\n",
    "\n",
    "        training_loss = 0.0\n",
    "        training_accuracy = 0.0\n",
    "        running_loss = 0.0\n",
    "        net = net.train()\n",
    "\n",
    "        # Calculate the number of batches to loop over\n",
    "        num_batches_to_loop = int(CONFIG.training_data_per_epoch * len(trainloader))\n",
    "        with tqdm(enumerate(trainloader, 0), total=num_batches_to_loop, desc=\"Training Batches Epoch {} / {}\".format(epoch + 1, epochs)) as train_pbar:\n",
    "            for i, data in train_pbar:\n",
    "        \n",
    "                # get the inputs\n",
    "                if device == 'cuda':\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                else:\n",
    "                    inputs, labels = data\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                if CONFIG.use_amp:\n",
    "                    with torch.autocast(device_type=device, dtype=torch.float16, enabled=CONFIG.use_amp):\n",
    "\n",
    "                        # forward + backward + optimize\n",
    "                        outputs = net(inputs)\n",
    "\n",
    "                        if CONFIG.use_mixup:\n",
    "                            loss_value = train_with_mixup(inputs, labels, outputs, criterion=criterion)\n",
    "                        else:\n",
    "                            loss_value = criterion(outputs,labels)\n",
    "\n",
    "                    # loss_value.backward()\n",
    "                    # optimizer.step()\n",
    "                    scaler.scale(loss_value).backward()\n",
    "                    scaler.step(optimizer)\n",
    "                    scaler.update()\n",
    "                else:\n",
    "                    # forward + backward + optimize\n",
    "                    outputs = net(inputs)\n",
    "\n",
    "                    if CONFIG.use_mixup:\n",
    "                        loss_value = train_with_mixup(inputs, labels, outputs, criterion=criterion)\n",
    "                    else:\n",
    "                        loss_value = criterion(outputs,labels)\n",
    "\n",
    "                    loss_value.backward()\n",
    "                    optimizer.step()\n",
    "\n",
    "                # print statistics and write to log\n",
    "                running_loss += loss_value.item()\n",
    "                training_loss += loss_value.item()\n",
    "\n",
    "                train_pbar.set_postfix(loss=(running_loss / ((i + 1) * trainloader.batch_size)))\n",
    "                training_accuracy += (outputs.argmax(1) == labels.argmax(1)).sum().item()\n",
    "\n",
    "                if i >= num_batches_to_loop:\n",
    "                    break\n",
    "\n",
    "        if type(scheduler).__name__ != 'NoneType':\n",
    "            scheduler.step()\n",
    "\n",
    "        training_loss = training_loss / (len(trainloader.dataset) * CONFIG.training_data_per_epoch)\n",
    "        training_loss_list[epoch] = training_loss\n",
    "        training_accuracy = 100 * training_accuracy / (len(trainloader.dataset) * CONFIG.training_data_per_epoch)\n",
    "        training_accuracy_list[epoch] = training_accuracy\n",
    "\n",
    "        logging.info('Batch {:5d} / {:5d}: Training Loss = {:.3f}, Training Accuracy = {:.3f}'.format(epoch + 1, epochs, training_loss, training_accuracy))\n",
    "\n",
    "        running_loss = 0.0\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        predictions_array = np.zeros((len(valloader.dataset), len(valloader.dataset.species)), dtype=float)\n",
    "        solutions_array = np.zeros((len(valloader.dataset), len(valloader.dataset.species)), dtype=float)\n",
    "        net = net.eval()\n",
    "        with tqdm(enumerate(valloader, 0), total=len(valloader), desc=\"Validation Batches Epoch {} / {}\".format(epoch + 1, epochs)) as val_pbar:\n",
    "            for i, data in val_pbar:\n",
    "                # get the inputs\n",
    "                if device == 'cuda':\n",
    "                    inputs, labels = data[0].to(device), data[1].to(device)\n",
    "                else:\n",
    "                    inputs, labels = data\n",
    "                    \n",
    "                # forward + backward + optimize\n",
    "                outputs = net(inputs)\n",
    "                loss_value = criterion(outputs, labels)\n",
    "\n",
    "                # print statistics and write to log\n",
    "                running_loss += loss_value.item()\n",
    "                val_loss += loss_value.item()\n",
    "\n",
    "                # Get model output and label to array\n",
    "                curr_predictions_array = toProb(outputs).detach().cpu().numpy()\n",
    "                predictions_array[i*valloader.batch_size:(i+1)*valloader.batch_size,:] = curr_predictions_array\n",
    "                curr_solutions_array = labels.detach().cpu().numpy()\n",
    "                solutions_array[i*valloader.batch_size:(i+1)*valloader.batch_size,:] = curr_solutions_array\n",
    "\n",
    "                # Update progress bar\n",
    "                val_pbar.set_postfix(loss=(running_loss / ((i + 1) * trainloader.batch_size)))\n",
    "                correct += (outputs.argmax(1) == labels.argmax(1)).sum().item()\n",
    "        \n",
    "        # Get cMAP\n",
    "        cmap_5 = padded_cmap(solution=pd.DataFrame(solutions_array), submission=pd.DataFrame(predictions_array), padding_factor=5)\n",
    "\n",
    "        # Get Metrics\n",
    "        val_loss = val_loss / len(valloader.dataset)\n",
    "        validation_loss_list[epoch] = val_loss\n",
    "        val_accuracy = 100 * correct / len(valloader.dataset)\n",
    "        validation_accuracy_list[epoch] = val_accuracy\n",
    "        cmap_5_list[epoch] = cmap_5\n",
    "\n",
    "        logging.info('Batch {:5d} / {:5d}: Validation Loss = {:.3f}, Validation Accuracy = {:.3f}, cmap score = {:.3f}'.format(epoch + 1, epochs, val_loss, val_accuracy, cmap_5))\n",
    "\n",
    "        save_weights = os.path.join(savePth,'model_weights.pth')\n",
    "        if cmap_5 > best_validation_cmap:\n",
    "            best_validation_cmap = cmap_5\n",
    "            best_state_dictionary = copy.deepcopy(net.state_dict())\n",
    "            # save network\n",
    "            torch.save(best_state_dictionary, save_weights)\n",
    "            inertia = 0\n",
    "            logging.info('Epoch {:5d} / {:5d} saved: New Best Epoch!'.format(epoch + 1, epochs))\n",
    "        else:\n",
    "            inertia += 1\n",
    "            if inertia == patience:\n",
    "                if best_state_dictionary is None:\n",
    "                    raise Exception(\"State dictionary should have been updated at least once\")\n",
    "                break\n",
    "        # print(f\"Validation accuracy: {val_accuracy}\")\n",
    "\n",
    "    logging.info('Finished Training')\n",
    "\n",
    "    output = {'validation_loss': validation_loss_list,\n",
    "              'validation_accuracy': validation_accuracy_list,\n",
    "              'training_loss': training_loss_list,\n",
    "              'training_accuracy': training_accuracy_list,\n",
    "              'cmap_5_scores': cmap_5_list}\n",
    "    \n",
    "    return output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run Training Procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main_train():\n",
    "\n",
    "    # Change Output path\n",
    "    folder_name = time.strftime('%Y-%m-%d_%H-%M-%S')\n",
    "    outpath = os.path.join(CONFIG.outpath, folder_name)\n",
    "    CONFIG.outpath = outpath\n",
    "    # Create Output directory\n",
    "    os.makedirs(CONFIG.outpath, exist_ok=True)\n",
    "\n",
    "    # Create Logger\n",
    "    logger = create_logger(final_output_path=CONFIG.outpath)\n",
    "\n",
    "    # Get all variable to logger\n",
    "    logger.info('############################################ START CONFIG FILE ############################################')\n",
    "    for attr, value in vars(CONFIG).items():\n",
    "        logger.info(f\"{attr}: {value}\")\n",
    "    logger.info('############################################  END CONFIG FILE  ############################################')\n",
    "\n",
    "    network = Mel_Classifier(model_name=CONFIG.model_name)\n",
    "    if CONFIG.load_pretrained_weights == True:\n",
    "        logger.info('Load PreTrained Weigths')\n",
    "        network.load_state_dict(torch.load(CONFIG.pretrained_weights, map_location=CONFIG.device))\n",
    "\n",
    "    if CONFIG.fix_features == True:\n",
    "        for param in network.backbone.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "    if CONFIG.class_weighting == True:\n",
    "        class_weights = torch.tensor(make_class_weights(train_dataset))\n",
    "        criterion = CONFIG.criterion(weight=class_weights)\n",
    "    else:\n",
    "        criterion = CONFIG.criterion()\n",
    "        \n",
    "    if CONFIG.optimizer == 'adam':\n",
    "        optimizer = torch.optim.Adam(filter(lambda p: p.requires_grad, network.parameters()), lr=CONFIG.lr, weight_decay=CONFIG.weight_decay)\n",
    "    elif CONFIG.optimizer == 'sgd':\n",
    "        optimizer = torch.optim.SGD(filter(lambda p: p.requires_grad, network.parameters()), lr=CONFIG.lr, momentum=CONFIG.momentum)\n",
    "    if CONFIG.scheduler == 'cosineannealing':\n",
    "        scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "                            optimizer, \n",
    "                            T_0=CONFIG.epochs, \n",
    "                            T_mult=CONFIG.T_mult, \n",
    "                            eta_min=CONFIG.eta_min, \n",
    "                            last_epoch=CONFIG.last_epoch\n",
    "                        )\n",
    "    elif CONFIG.scheduler == None:\n",
    "        CONFIG.scheduler = None\n",
    "\n",
    "    # Train Net\n",
    "    output = train_net( net=network,\n",
    "                        trainloader=train_loader,\n",
    "                        valloader=valid_loader,\n",
    "                        criterion=criterion,\n",
    "                        optimizer=optimizer,\n",
    "                        logging=logger,\n",
    "                        scheduler=scheduler,\n",
    "                        epochs=CONFIG.epochs,\n",
    "                        device=CONFIG.device,\n",
    "                        print_every_samples=CONFIG.print_every_n_batches,\n",
    "                        savePth=CONFIG.outpath,\n",
    "                        patience=CONFIG.patience\n",
    "                        )\n",
    "    \n",
    "    # Save Output\n",
    "    outputName = 'training_prog.json'\n",
    "    jsonpath = os.path.join(CONFIG.outpath, outputName)\n",
    "    with open(jsonpath, 'w') as json_file:\n",
    "        json.dump(output, json_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "main_train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Kaggle: Zip Directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import os\n",
    "from IPython.display import FileLink\n",
    "\n",
    "# https://www.kaggle.com/code/hari31416/downloading-file-and-directory-from-kaggle\n",
    "def zip_dir(directory = os.curdir, file_name = 'directory.zip'):\n",
    "    \"\"\"\n",
    "    zip all the files in a directory\n",
    "    \n",
    "    Parameters\n",
    "    _____\n",
    "    directory: str\n",
    "        directory needs to be zipped, defualt is current working directory\n",
    "        \n",
    "    file_name: str\n",
    "        the name of the zipped file (including .zip), default is 'directory.zip'\n",
    "        \n",
    "    Returns\n",
    "    _____\n",
    "    Creates a hyperlink, which can be used to download the zip file)\n",
    "    \"\"\"\n",
    "    os.chdir(directory)\n",
    "    zip_ref = zipfile.ZipFile(file_name, mode='w')\n",
    "    for folder, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file_name in file:\n",
    "                pass\n",
    "            else:\n",
    "                zip_ref.write(os.path.join(folder, file))\n",
    "\n",
    "    return FileLink(file_name)\n",
    "\n",
    "if CONFIG.run_environment == 'kaggle':\n",
    "    zip_dir()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Fix issue that not all labels are in validation set\n",
    "# TODO: Fix progress bar\n",
    "# TODO: adam?\n",
    "# TODO: cMAP\n",
    "# TODO: Train with mixup    \n",
    "# TODO: Dataset metrics\n",
    "# TODO: Uniform sampler accross classes\n",
    "# TODO: class weights\n",
    "# TODO: use only sub-dataset per epoch?\n",
    "# TODO: consider second label\n",
    "# TODO: Inference Script\n",
    "\n",
    "# TODO: add no-call samples\n",
    "# TODO: augmentations\n",
    "# TODO: include rating"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try class weights by 1st rank:\n",
    "sample_weights = (\n",
    "    all_primary_labels.value_counts() / \n",
    "    all_primary_labels.value_counts().sum()\n",
    ")  ** (-0.5)\n",
    "\n",
    "Also by 1st rank:\n",
    "\n",
    "Small inference tricks\n",
    "\n",
    "    Using temperature mean: pred = (pred**2).mean(axis=0) ** 0.5\n",
    "    Using Attention SED probs * 0.75 + Max Timewise probs * 0.25\n",
    "\n",
    "All these gave marginal improvements but it is was a matter of first 3 places :) "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
